{
  "name": "LLM-Agent",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "llm-analyze",
        "responseMode": "onReceived",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [240, 300],
      "id": "llm-webhook-in"
    },
    {
      "parameters": {
        "provider": "={{ $env.LLM.provider }}",
        "apiKey": "={{ $env.LLM.apiKey }}",
        "model": "={{ $env.LLM.model }}",
        "prompt": "=# Task\nAnalyze the following data and provide insights:\n\n## Source\nSource Type: {{ $json.source_type }}\nSource: {{ $json.source_system || 'N/A' }}\nStatus: {{ $json.status }}\n\n## Content\nTitle: {{ $json.title }}\nDescription: {{ $json.description || 'No description provided' }}\n\n## Tasks\n1. Categorize this item (bug, feature, documentation, question, etc.)\n2. Suggest a priority level (low, medium, high, critical)\n3. Identify any related components or systems\n4. Suggest possible assignees based on the content\n5. Provide a brief summary of the issue or task\n\nRespond in JSON format with the following structure:\n{\n  \"category\": \"string\",\n  \"priority\": \"string\",\n  \"components\": [\"string\"],\n  \"suggested_assignees\": [\"string\"],\n  \"summary\": \"string\",\n  \"action_items\": [\"string\"]\n}",
        "options": {
          "maxTokens": 1000,
          "temperature": 0.3
        }
      },
      "type": "n8n-nodes-base.openAi",
      "typeVersion": 1,
      "position": [460, 300],
      "id": "analyze-with-llm"
    },
    {
      "parameters": {
        "mode": "jsonParse",
        "property": "result",
        "options": {}
      },
      "type": "n8n-nodes-base.setJsonProperty",
      "typeVersion": 1,
      "position": [660, 300],
      "id": "parse-llm-response"
    },
    {
      "parameters": {
        "mode": "jsonToJson",
        "jsonInput": "={{ $json }}",
        "options": {
          "dotNotation": true
        },
        "jsonOutput": "={\n  ...($json),\n  ...($json.result),\n  llm_analyzed: true,\n  original_data: $json\n}"
      },
      "type": "n8n-nodes-base.itemBinary",
      "typeVersion": 1,
      "position": [840, 300],
      "id": "merge-llm-analysis"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "llm-result",
        "responseMode": "lastNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [1020, 300],
      "id": "llm-webhook-out"
    }
  ],
  "connections": {
    "llm-webhook-in": {
      "main": [
        [
          {
            "node": "analyze-with-llm",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "analyze-with-llm": {
      "main": [
        [
          {
            "node": "parse-llm-response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "parse-llm-response": {
      "main": [
        [
          {
            "node": "merge-llm-analysis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "merge-llm-analysis": {
      "main": [
        [
          {
            "node": "llm-webhook-out",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "saveExecutionProgress": true,
    "saveManualExecutions": true
  }
}
